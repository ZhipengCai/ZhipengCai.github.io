<html>
<head>
	<meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
	<title>Zhipeng Cai</title>
	<meta content="Zhipeng Cai, ZhipengCai.github.io" name="keywords" />
	<style media="screen" type="text/css">html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, font, img, ins, kbd, q, s, samp, small, strike, strong, sub, tt, var, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td {
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}
a {
  color: #1772d0;
  text-decoration:none;
}
a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
}
a.paper {
  font-weight: bold;
  font-size: 12pt;
}
b.paper {
  font-weight: bold;
  font-size: 12pt;
}
* {
  margin: 0pt;
  padding: 0pt;
}
body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 1600px;
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  background: #eee;
}
h2 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15pt;
  font-weight: 700;
}
h3 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 16px;
  font-weight: 700;
}
strong {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
  font-weight:bold;
}
		
Highlight {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15px;
  font-weight:bold;
	color: red;
}
		
ul { 
  list-style: circle;
}
img {
  border: none;
}
li {
  padding-bottom: 0.5em;
  margin-left: 1.4em;
}
alert {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
  font-weight: bold;
  color: #FF0000;
}
em, i {
	font-style:italic;
}
div.section {
  clear: both;
  margin-bottom: 1.5em;
  background: #eee;
}
div.spanner {
  clear: both;
}
div.paper {
  clear: both;
  margin-top: 0.5em;
  margin-bottom: 1em;
  border: 1px solid #ddd;
  background: #fff;
  padding: 1em 1em 1em 1em;
}
div.paper div {
  padding-left: 230px;
}
img.paper {
  margin-bottom: 0.5em;
  float: left;
  width: 200px;
}
span.blurb {
  font-style:italic;
  display:block;
  margin-top:0.75em;
  margin-bottom:0.5em;
}
pre, code {
  font-family: 'Lucida Console', 'Andale Mono', 'Courier', monospaced;
  margin: 1em 0;
  padding: 0;
}
div.paper pre {
  font-size: 0.9em;
}
</style>

<link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css" /><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>--><!--<link href='http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz' rel='stylesheet' type='text/css'>-->
</head>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-66888300-1', 'auto');
  ga('send', 'pageview');
</script>
<body>
<div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 180px;">
<div style="margin: 0px auto; width: 100%;">
<img title="ZhipengCai"style="float: left; padding-left: .01em; height: 180px;" src="avatar2.jpg" />
<div style="padding-left: 20em; vertical-align: top; height: 120px;">
<span style="line-height: 150%; font-size: 20pt;">蔡志鹏（Zhipeng Cai）</span><br />
<span>Research scientist at Intel Embodied AI Lab, Santa Clara, California, USA. </span><br />
<span>Education: PhD of Computer Science at <a href='https://www.adelaide.edu.au/'>The University of Adelaide</a>, Australia. Supervisor: Prof. <a href='http://cs.adelaide.edu.au/~tjchin/doku.php'>Tat-Jun Chin</a> &amp; Prof. <a href='https://cs.adelaide.edu.au/~dsuter/'>David Suter</a>. </span> <br /> 
<span><Highlight>Email</Highlight>: <strong> czptc2h@gmail.com </strong> </span> <br /> 
<span><a href='https://scholar.google.com/citations?user=AZNUIDAAAAAJ&hl=en'>Google Scholar</a></span><br />
</div>
</div>
</div>
<!--<div style="clear: both; background-color: #fff; margin-top: 1.5em; padding: .2em; padding-left: .3em;">-->

<!--
<div style="clear: both;">
<div class="section">
<h2>About Me (<a href='cv.pdf'>CV</a>)</h2>
<div class="paper"> 
	coming soon...
<br> <br>
</div>
</div>
</div>
-->
	
	<!--
<div style="clear: both;">
<div class="section">
  <h2>Note</h2>
  <div class="paper">
    <ul>
	<li>Some papers are linked to the arxiv version due to some modifications after publication. Please follow the link to prevent misunderstandings :).</li>
    </ul>
  </div>
</div>
</div>
	-->
<div style="clear: both;">
<div class="section">
  <h2>About me</h2>
  <div class="paper">
    <ul>
	<span> I am interested in general machine learning and computer vision problems. During PhD, I was interested in robust geometric perception, which estimates computer vision models (correspondences between images, poses, 3D reconstructions) given outlier contaminated data. I was specifically interested in designing efficient algorithms that have optimality guarantees, i.e., guarantee to return the best solution. 
		After joining Intel, my interests shift towards a mixture of learning and vision, where I study various problems such as 1) learning-based perception (feature matching, finding correspondences, pose estimation, depth estimation etc) 2) Continual Learning 3) Generative models (e.g., novel view synthesis, image/3D scene generation). My work has been selected as one of the 12 best papers at ECCV'18. <br /> 
		I have (co-)supervised Ph.D students/interns from different contries. I am actively looking for good students (Send me an email if you are interested in internships/collaborations). </span> 	
    </ul>
  </div>
</div>
</div>
	
<div style="clear: both;">
<div class="section">
  <h2>News</h2>
  <div class="paper">
    <ul>
	<li> <img src="hot_wide.png" class="media" alt="" height = "17" width="39" /> Paper accepted (topic: object detection in remote sensing images) to <a href = 'https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=36'> IEEE Transactions on Geoscience and Remote Sensing (TGRS) </a>  (Aug-2023). </li>
	<li> <img src="hot_wide.png" class="media" alt="" height = "17" width="39" /> Two papers (topic: 1. continual learning on NeRFs 2. zero-shot metric depth estimation) accepted to <a href = 'https://iccv2023.thecvf.com/'> ICCV 2023 </a> (July-2023). </li>
	<li> <img src="blank_wide.png" class="media" alt="" height = "17" width="39" /> SimCS accepted to <a href = 'https://sites.google.com/view/clvision2023'> CVPR 2023 Workshop on Continual Learning in Computer Vision </a>. </li>
	<li> <img src="blank_wide.png" class="media" alt="" height = "17" width="39" /> Co-organizing the <a href = 'https://sites.google.com/andrew.cmu.edu/gpr-competition/'> ICRA 2022 Gereral Place Recognition Competition </a>. </li>
	<li> <img src="blank_wide.png" class="media" alt="" height = "17" width="39" /> Paper accepted to <a href='http://iccv2021.thecvf.com/home'> ICCV2021 </a>! Subject: online continual learning. (22-Jul-2021)</li>
	<li> <img src="blank_wide.png" class="media" alt="" height = "17" width="39" /> Got my Ph.D degree (my <a href='https://digital.library.adelaide.edu.au/dspace/bitstream/2440/127452/1/Cai2020_PhD.pdf'>thesis</a> was awarded the <a href='https://www.adelaide.edu.au/graduatecentre/current-students/your-thesis-examination/research-student-excellence-awards'>Dean’s Commendation for Doctoral Thesis Excellence</a>)! Now a postdoc at Intel Intelligent Systems Lab. (Sep-2020) </li>
	<li> <img src="blank_wide.png" class="media" alt="" height = "17" width="39" /> Served as a "wingman" during TJ's <a href='http://cmp.felk.cvut.cz/cvpr2020-ransac-tutorial/'> RANSAC CVPR 2020 Tutorial </a>. Find me <a href='https://youtu.be/WkN3FP_jbuI/'> here </a> (June-2020)</li>
	<li> <img src="blank_wide.png" class="media" alt="" height = "17" width="39" /> Paper accepted to IJCV Special Issue on Best of ECCV 2018 (July-2019)</li>
	<li> <img src="blank_wide.png" class="media" alt="" height = "17" width="39" /> Paper accepted as <Highlight> oral </Highlight> presentation to <a href='https://http://iccv2019.thecvf.com/'> ICCV2019 </a>! Subject: robust fitting. (22-Jul-2019)</li>
	<li> <img src="blank_wide.png" class="media" alt="" height = "17" width="39" /> Internship at <a href = 'http://vladlen.info/lab/'>Intel Intelligent Systems Lab</a> at Silicon Valley. Working with Dr. <a href = 'http://vladlen.info/'>Vladlen Koltun</a>. (Jan-2019 to July-2019)</li>
	<li> <img src="blank_wide.png" class="media" alt="" height = "17" width="39" /> Paper "Robust fitting in computer vision: easy or hard?" has been selected as <Highlight>one of the 12 best papers of ECCV2018</Highlight> (20-Nov-2018)</li>
	<li> <img src="blank_wide.png" class="media" alt="" height = "17" width="39" /> Paper accepted to <a href='https://www.journals.elsevier.com/isprs-journal-of-photogrammetry-and-remote-sensing'>ISPRS Journal of Photogrammetry and Remote Sensing </a>. Subject: point cloud registration. (14-Nov-2018)</li>    
	<li> <img src="blank_wide.png" class="media" alt="" height = "17" width="39" /> Two papers accepted as <Highlight> oral </Highlight> presentation to <a href='https://eccv2018.org/'> ECCV2018 </a>! Subject: robust fitting. (4-Jul-2018)</li>
    </ul>
  </div>
</div>
</div>

<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Publication</h2>
<h2 id="confpapers">Note: The arXiv link (if available) of each paper contains modifications after publication. </h2>	

<h2 id="confpapers">2023</h2>

<div class="paper" id="TGRS23"><img class="paper" src="papers/TGRS23.png" title="TGRS23" />
<div> GSDDet: Ground Sample Distance Guided Object Detection for Remote Sensing Images <br />
Yunuo Yang, <strong> Zhipeng Cai </strong>, Pinqing Song, Yu Zang, Guanjie Huang, Ming Cheng, Cheng Wang <br />
IEEE Transactions on Geoscience and Remote Sensing (TGRS)<br />
[Paper (coming soon)]
</div>
<div class="spanner"></div>
</div>
	
<div class="paper" id="ICCV23_CLNeRF"><img class="paper" src="papers/CLNeRF.png" title="CLNeRF23" />
<div> CLNeRF: Continual Learning Meets NeRF <br />
<strong> Zhipeng Cai </strong>, Matthias Müller <br />
International Conference on Computer Vision (ICCV) 2023<br />
[Paper (coming soon)]
<a href='https://github.com/IntelLabs/CLNeRF'>[Code]</a>
<a href='https://huggingface.co/datasets/IntelLabs/WAT-WorldAcrossTime'>[dataset]</a>
<br />
<iframe width="400" height="225" src="https://www.youtube.com/embed/QDPSpKIFlG0?si=c9Dayyqefe4IhI0d" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
</div>
<div class="spanner"></div>
</div>

<div class="paper" id="ICCV23_Metric3D"><img class="paper" src="papers/ICCV23_Metric3D.png" title="ICCV23_Metric3D.png" />
<div> Metric3D: Towards Zero-shot Metric 3D Prediction from A Single Image <br />
Wei Yin, Chi Zhang, Hao Chen, <strong> Zhipeng Cai </strong>, Xiaozhi Chen, Kaixuan Wang, Gang Yu, Chunhua Shen <br />
International Conference on Computer Vision (ICCV) 2023<br />
<a href='https://arxiv.org/pdf/2307.10984v1.pdf'>[ArXiv preprint]</a>
<a href='https://github.com/YvanYin/Metric3D'>[Code]</a>
</div>
<div class="spanner"></div>
</div>

<div class="paper" id="ICCV23_OCL"><img class="paper" src="papers/OCL23.png" title="ArXiv23_OCL" />
<div> Online Continual Learning Without the Storage Constraint <br />
Ameya Prabhu, <strong> Zhipeng Cai </strong>, Puneet Dokania, Philip Torr, Vladlen Koltun, Ozan Sener <br />
<a href='https://arxiv.org/pdf/2305.09253.pdf'>[ArXiv preprint]</a>
<a href='https://github.com/drimpossible/ACM'>[Code]</a>
</div>
<div class="spanner"></div>
</div>

	
<div class="paper" id="ICCV23_TTT"><img class="paper" src="papers/online_TTT.png" title="ArXiv23_TTT" />
<div> Revisiting Test Time Adaptation under Online Evaluation <br />
Motasem Alfarra, Hani Itani, Alejandro Pardo, Shyma Alhuwaider, Merey Ramazanova, Juan C. Pérez,  <strong> Zhipeng Cai </strong>, Matthias Müller, Bernard Ghanem <br />
<a href='https://arxiv.org/pdf/2304.04795.pdf'>[ArXiv preprint]</a>
<a href='https://github.com/MotasemAlfarra/Online_Test_Time_Adaptation'>[Code]</a>
</div>
<div class="spanner"></div>
</div>
	
<h2 id="confpapers">2022</h2>
<div class="paper" id="CVPR23"><img class="paper" src="papers/SimCS.png" title="ArXiv23" />
<div> SimCS: Simulation for Online Domain-Incremental Continual Segmentation<br />
Motasem Alfarra, <strong> Zhipeng Cai </strong>, Adel Bibi, Bernard Ghanem, Matthias Muller <br />
CVPR Workshop on Continual Learning (CLVision) 2023 <br />
<a href='https://arxiv.org/pdf/2211.16234.pdf'>[ArXiv preprint]</a>
</div>
<div class="spanner"></div>
</div>
	
<div class="paper" id="ICLR23"><img class="paper" src="papers/AMA.png" title="ArXiv22" />
<div> Improving Information Retention in Large Scale Online Continual Learning<br />
<strong>Zhipeng Cai</strong>, Vladlen Koltun, Ozan Sener <br />
<a href='https://arxiv.org/pdf/2210.06401.pdf'>[ArXiv preprint]</a>
</div>
<div class="spanner"></div>
</div>
	
<h2 id="confpapers">2021</h2>
<div class="paper" id="ICCV21"><img class="paper" src="papers/CLOC.png" title="ICCV21" />
<div> Online Continual Learning with Natural Distribution Shifts: An Empirical Study with Visual Data<br />
<strong>Zhipeng Cai</strong>, Ozan Sener, Vladlen Koltun <br />
International Conference on Computer Vision (ICCV) 2021<br />
<a href='https://arxiv.org/pdf/2108.09020.pdf'>[ArXiv preprint]</a>
<a href='https://github.com/IntelLabs/continuallearning/tree/main/CLOC'>[Code]</a>
<br />
<iframe width="400" height="225" src="https://www.youtube.com/embed/-FO2Khwjprg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
<div class="spanner"></div>
</div>
	
<h2 id="confpapers">2020</h2>

<div class="paper" id="Thesis">
<div> Consensus Maximization: Theoretical Analysis and New Algorithms<br />
<strong> Zhipeng Cai </strong> <br />
Ph.D thesis (Supervised by: Prof. Tat-Jun Chin and Prof. David Suter) <br />
<a href='https://digital.library.adelaide.edu.au/dspace/bitstream/2440/127452/1/Cai2020_PhD.pdf'>[PDF]</a>
</div>
<div class="spanner"></div>
</div>

	
<div class="paper" id="ECCV20">
<div> Globally Optimal and Efficient Vanishing Point Estimation in Atlanta World<br />
Haoang Li, Pyojin Kim, Ji Zhao, Kyungdon Joo, <strong>Zhipeng Cai</strong>, Zhe Liu, Yun-Hui Liu <br />
European Conference on Computer Vision (ECCV) 2020<br />
<a href='https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123670154.pdf'>[Paper]</a>
</div>
<div class="spanner"></div>
</div>

	
<h2 id="confpapers">2019</h2>

<div class="paper" id="JICV19_Hardness"><img class="paper" src="papers/ECCV18_Hardness.png" title="IJCV19_Hardness" />
<div> Robust fitting in computer vision: easy or hard?<br />
Tat-Jun Chin, <strong>Zhipeng Cai</strong>, Frank Neumann <br />
International Journal on Computer Vision (IJCV), <Highlight>Special Issue on Best of ECCV 2018</Highlight>. <br />
<a href='https://rd.springer.com/content/pdf/10.1007%2Fs11263-019-01207-y.pdf'>[Paper]</a>
</div>
<div class="spanner"></div>
</div>

<!-- <div class="paper" id="ICCV19"><img class="paper" src="papers/ICCV19.png" title="ICCV19" />
<div> Consensus Maximization Tree Search Revisited <br />
<strong>Zhipeng Cai</strong>, Tat-Jun Chin, Vladlen Koltun <br />
International Conference on Computer Vision (ICCV) 2019, <Highlight>oral</Highlight> presentation. <br />
<a href='https://arxiv.org/abs/1908.02021'>[Arxiv preprint]</a>
<a href='https://github.com/ZhipengCai/MaxConTreeSearch'> [Code] </a>
<br />
<iframe width="400" height="225" src="https://youtube.videoken.com/embed/my3jocjpD0U?tocItem=157&autoplay=0" frameborder="0" allow="accelerometer; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
<div class="spanner"></div>
</div> -->
<div class="paper" id="ICCV19">
    <img class="paper" src="papers/ICCV19.png" title="ICCV19" />
    <div>
        Consensus Maximization Tree Search Revisited <br />
        <strong>Zhipeng Cai</strong>, Tat-Jun Chin, Vladlen Koltun <br />
        International Conference on Computer Vision (ICCV) 2019, <Highlight>oral</Highlight> presentation. <br />
        <a href='https://arxiv.org/abs/1908.02021'>[Arxiv preprint]</a>
        <a href='https://github.com/ZhipengCai/MaxConTreeSearch'> [Code] </a>
        <br />

        <!-- This div will be replaced with the YouTube video iframe -->
        <div id="player"></div>

        <script src="https://www.youtube.com/iframe_api"></script>
        <script>
            var player;
            var initialized = false;

            function onYouTubeIframeAPIReady() {
                player = new YT.Player('player', {
                    height: '225',
                    width: '400',
                    videoId: 'my3jocjpD0U',
                    playerVars: {
                        'start': 5633,
                        'autoplay': 0
                    },
                    events: {
                        'onReady': onPlayerReady
                    }
                });
            }

            function onPlayerReady(event) {
                event.target.playVideo();
		player.pauseVideo();
            }

            // function onPlayerStateChange(event) {
            //     if (event.data == YT.PlayerState.PLAYING && !initialized) {
            //         player.pauseVideo();
            //         initialized = true;
            //     }
            // }
        </script>
    </div>
    <div class="spanner"></div>
</div>






<div class="paper" id="ISPRSJ18"><img class="paper" src="papers/Reg_Arch_visual_4.png" title="ISPRSJ18" />
<div> Practical Optimal Registration of Terrestrial LiDAR Scan Pairs<br />
<strong>Zhipeng Cai</strong>, Tat-Jun Chin, Alvaro Parra Bustos, Konrad Schindler <br />
ISPRS Journal of Photogrammetry and Remote Sensing, 2019. <br />
<a href='http://arxiv.org/abs/1811.09962'>[Arxiv preprint]</a>
<a href='https://www.sciencedirect.com/science/article/pii/S0924271618303125?via%3Dihub'>[PDF]</a> 
<a href='https://github.com/ZhipengCai/Demo---Practical-optimal-registration-of-terrestrial-LiDAR-scan-pairs'>[Code]</a> 
<!--<a href='https://youtu.be/MKzSN4bbs1o'>[Video]</a>--> 
<br />
<iframe width="400" height="225" src="https://www.youtube.com/embed/MKzSN4bbs1o" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
<div class="spanner"></div>
</div>

<h2 id="confpapers">2018</h2>

<div class="paper" id="ECCV18_IBCO"><img class="paper" src="papers/ECCV18_IBCO.png" title="ECCV18_IBCO" />
<div> Deterministic consensus maximization with biconvex programming<br />
<strong>Zhipeng Cai</strong>, Tat-Jun Chin, Huu Le, David Suter <br />
European Conference on Computer Vision (ECCV) 2018, <Highlight>oral</Highlight> presentation. <br />
<a href='https://arxiv.org/abs/1807.09436'>[Arxiv preprint]</a> 
<a href='https://github.com/ZhipengCai/Demo---Deterministic-consensus-maximization-with-biconvex-programming'> [Code] </a>
<a href='https://drive.google.com/open?id=1Cm0mHk52RkGB23rslaYiFoy7Md4XaXzx'> [Slides] </a>
<br />
<iframe width="400" height="225" src="https://www.youtube.com/embed/gE6zkCEC9dA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
<div class="spanner"></div>
</div>
	
<div class="paper" id="ECCV18_Hardness"><img class="paper" src="papers/ECCV18_Hardness.png" title="ECCV18_Hardness" />
<div> Robust fitting in computer vision: easy or hard?<br />
Tat-Jun Chin, <strong>Zhipeng Cai</strong>, Frank Neumann <br />
European Conference on Computer Vision (ECCV) 2018, <Highlight>oral</Highlight> presentation.<br />
<Highlight>Selected as one of the 12 best papers from the conference </Highlight><br />
<a href='https://arxiv.org/abs/1802.06464'>[Arxiv preprint]</a> 
<a href='https://drive.google.com/open?id=14muETTtSj-yMGR_PLRmCgC4sqXN1Hi8p'> [Slides] </a>
<br />
<iframe width="400" height="225" src="https://www.youtube.com/embed/VpJ56rsimzM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
<div class="spanner"></div>
</div>

<h2 id="confpapers">2016</h2>

<div class="paper" id="ITS16_Wen">
<div> Spatial-Related Traffic Sign Inspection for Inventory Purposes Using Mobile Laser Scanning Data<br />
Chenglu Wen, Jonathan Li, Huan Luo, Yongtao Yu, <strong>Zhipeng Cai</strong>, Hanyun Wang, Cheng Wang <br />
IEEE Transactions on Intelligent Transportation Systems, 2016 <br />
<a href='https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7089251'>[PDF]</a> <br />
</div>
<div class="spanner"></div>
</div>
	
<div class="paper" id="ITS16_Luo">
<div> Patch-based semantic labeling of road scene using colorized mobile LiDAR point clouds<br />
Huan Luo, Cheng Wang, Chenglu Wen, <strong>Zhipeng Cai</strong>, Ziyi Chen, Hanyun Wang, Yongtao Yu, Jonathan Li <br />
IEEE Transactions on Intelligent Transportation Systems, 2016 <br />
<a href='https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7345561'>[PDF]</a> <br />
</div>
<div class="spanner"></div>
</div>	
	
	
<h2 id="confpapers">2015</h2>
	
<div class="paper" id="GRSL16"><img class="paper" src="papers/GRSL16.png" title="Occluded Boundary Detection for Small-footprint Ground-borne LIDAR Point Cloud Guided by Last-echo" />
<div>Occluded Boundary Detection for Small-footprint Ground-borne LIDAR Point Cloud Guided by Last-echo<br />
<strong>Zhipeng Cai</strong>, Cheng Wang, Chenglu Wen, Jonathan Li   <br />
IEEE Geoscience and Remote Sensing Letters, 2015 <br />
<a href='https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7226818'>[PDF]</a> <br />
</div>
<div class="spanner"></div>
</div>	
	
<div class="paper" id="ICSDM15"><img class="paper" src="papers/ICSDM15.png" title="3D-PatchMach: an Optimization Algorithm for Point Cloud Completion" />
<div>
3D-PatchMach: an Optimization Algorithm for Point Cloud Completion<br />
<strong>Zhipeng Cai</strong>, Cheng Wang, Chenglu Wen, Jonathan Li   <br />
Second IEEE International Conference on Spatial Data Mining and Geographical Knowledge Services(ICSDM2015)<br />
<a href='https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7298044'>[PDF]</a><br /> 
</div>
<div class="spanner"></div>
</div>


<h2 id="confpapers">2012</h2>
	
<div class="paper" id="CVRS12_Wang">
<div> Automatic road extraction from mobile laser scanning data<br />
Hanyun Wang, <strong>Zhipeng Cai</strong>, Huan Luo, Cheng Wang, Peng Li, Wentao Yang, Suoping Ren, Jonathan Li   <br />
International Conference on Computer Vision in Remote Sensing (CVRS), 2012<br />
<a href='https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6421248'>[PDF]</a><br /> 
</div>
<div class="spanner"></div>
</div>
	
	
<div class="paper" id="CVRS12_Li_Scale">
<div> Scale invariant kernel-based object tracking<br />
 Peng Li,  <strong>Zhipeng Cai</strong>, Hanyun Wang, Zhuo Sun, Yunhui Yi, Cheng Wang, Jonathan Li <br />
International Conference on Computer Vision in Remote Sensing (CVRS), 2012<br />
<a href='https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6421270'>[PDF]</a><br /> 
</div>
<div class="spanner"></div>
</div>
	
	
<div class="paper" id="CVRS12_Li_Cascade">
<div> Cascade framework for object extraction in image sequences<br />
 Peng Li, <strong>Zhipeng Cai</strong>, Cheng Wang, Zhuo Sun, Hanyun Wang, Jonathan Li <br />
International Conference on Computer Vision in Remote Sensing (CVRS), 2012<br />
<a href='https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6421233'>[PDF]</a><br /> 
</div>
<div class="spanner"></div>
</div>
	
	
</div>
</div>


<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Patent:</h2>
<div class="paper">
<ul>
<p>1. Interactive three-dimensional point cloud color editing method. Publication number: <a href='https://www.google.com.au/patents/CN103489224A?cl=en&dq=Interactive+three-dimensional+point+cloud+color+editing+method&hl=zh-CN&sa=X&ved=0ahUKEwiFuIeNsbvQAhVBPY8KHRlyCWsQ6AEIGjAA'>CN 103489224 A</a><br /></p>
<p>2. Three-dimensional point cloud auto-completion method. Publication number: <a href='http://patentool.wanfangdata.com.cn/Patent/Details?id=CN201410308951.5'>CN 104063898 A</a><br /></p>
</ul>
	
</div>
</div>
</div>


<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Award</h2>
<div class="paper">
<ul>

<li>2020 <a href='https://www.adelaide.edu.au/graduatecentre/current-students/your-thesis-examination/research-student-excellence-awards'>Dean’s Commendation for Doctoral Thesis Excellence</a></li>	
<li>2018 Ranked the first 30th in the <a href='http://www.cvmart.net/activity/detail/1'>Ranking List of 2018 Potential Computer Vision Developers</a></li>	
<li>2016 Excellent Master Degree Graduation Thesis</li>
<li>2013 Excellent Bachelor Degree Graduation Thesis</li>
<li>2013 The CCF Outstanding Undergraduate Award</li>
<li>2012 The Meritorious Winner of 2012 Mathematical Contest In Modeling Certificate of Achievement</li>

</ul>
<div class="spanner"></div>
</div>
</div>
</div>

	
<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Working experience</h2>
<div class="paper">
<ul>
<li>Jan-2019 to June-2020: Internship at <a href = 'http://vladlen.info/lab/'>Intel Intelligent Systems Lab</a> at Santa Clara, CA, USA. Working with Dr. <a href = 'http://vladlen.info/'>Vladlen Koltun</a>.</li>
<li>July-2020 to May-2022: Postdoc at <a href = 'http://vladlen.info/lab/'>Intel Intelligent Systems Lab</a> at Santa Clara, CA, USA. Working with Dr. <a href = 'http://vladlen.info/'>Vladlen Koltun</a>.</li>
<li>June-2022 to Now: Research scientist at Intel Embodied AI Lab at Santa Clara, CA, USA. </li>

</ul>
<div class="spanner"></div>
</div>
</div>
</div>
	
<div style="clear: both;">
<div class="section">
<h2 id="confpapers">Academic Service</h2>
<div class="paper">
<ul>
<li>Conference reviewer: <a href='https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition'>CVPR</a>, <a href='https://en.wikipedia.org/wiki/International_Conference_on_Computer_Vision'>ICCV</a>, <a href='https://en.wikipedia.org/wiki/European_Conference_on_Computer_Vision'>ECCV</a>, <a href='http://www.aaai.org/Conferences/conferences.php'>AAAI</a>, <a href='https://iclr.cc/'>ICLR</a>, <a href='https://https://icml.cc//'>ICML</a> </li>
<li>Journal reviewer: <a href='https://mc.manuscriptcentral.com/tpami-cs'>TPAMI</a>, <a href= 'https://link.springer.com/journal/11263'> IJCV</a>, <a href='https://www.journals.elsevier.com/isprs-journal-of-photogrammetry-and-remote-sensing'>ISPRS Journal of Photogrammetry and Remote Sensing</a>, <a href='https://www.journals.elsevier.com/pattern-recognition'>Pattern Recognition</a>, <a href='https://www.ieee-ras.org/publications/ra-l'>RA-L</a> </li>
</ul>
<div class="spanner"></div>
</div>
</div>
</div>

<div style="clear:both;">
<p align="right"><font size="5">Last Updated on 22th Nov, 2016</font></p>
<p align="right"><font size="5">Published with <a href='https://pages.github.com/'>GitHub Pages</a></font></p>
</div>

<hr>
<div id="clustrmaps-widget"></div><script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?u=5eyy&d=BGOr6AsJEFlhvzuajVPFK8a99dHE3Edu1vy9kmu6b3M"></script>

</body>
</html>

    Contact GitHub API Training Shop Blog About 

    © 2016 GitHub, Inc. Terms Privacy Security Status Help 

